# Cannon Catch – Evolutionary Reinforcement Learning Game

Cannon Catch is a physics-based Pygame project in which a basket catches balls fired from a cannon.
The project includes a complete evolutionary reinforcement learning system that trains an AI agent to play the game and outperform human reaction limits.

The AI is trained using multi-agent neuroevolution with adaptive mutation and is deployed directly into the live game to control the basket in real time.

---

## Project Overview

This repository demonstrates a full end-to-end machine learning system:

- A custom real-time game environment built with Pygame
- A multi-agent evolutionary reinforcement learning trainer
- Adaptive mutation and elite selection
- Crash-safe training with automatic checkpointing
- Live visualization of the best-performing agent during training
- Deployment of the trained model into the actual game loop

After a short training period, the AI consistently achieves perfect performance (10/10 catches per episode).

---

## Game Mechanics

- A cannon positioned at the top center of the screen fires balls at random downward angles
- Balls follow realistic physics with gravity and wall/ceiling bounce
- A basket moves horizontally along the ground to catch the balls
- One ball is active at a time during training for stability
- An episode ends after:
  - 10 throws, or
  - 5 misses (early termination)

### Physics Configuration
- Gravity: 850.0 px/s²
- Basket speed: 1000 px/s
- Ball throw delay: 1.4 seconds

---

## Reinforcement Learning System

### Training Method
- Population-based evolutionary reinforcement learning (neuroevolution)
- No gradients or backpropagation
- Agents learn purely through selection and mutation

### Population Structure
- 10 agents per generation
- Top 5 agents survive (elite selection)
- Bottom 5 agents are removed
- New agents are generated by mutating elite agents

### Neural Network Architecture

Each agent is a small feedforward neural network:

- Input layer (5 values):
  - Basket x-position
  - Ball x-position
  - Ball y-position
  - Ball x-velocity
  - Ball y-velocity
- Hidden layers: 16 → 16
- Output layer: 3 discrete actions
  - Move left
  - Stay
  - Move right

---

## Adaptive Mutation Strategy

The mutation system automatically adjusts exploration based on performance:

- Mutation strength decreases when fitness improves
- Mutation strength increases when learning stagnates
- Prevents premature convergence while maintaining exploration

This allows the population to converge quickly while avoiding local optima.

---

## Fitness Function

Agents are evaluated per episode using:

fitness = (catches × 10) − (misses × 6) + (best_streak × 2)

Where:
- Catches reward successful behavior
- Misses penalize failure
- Best streak rewards consistency

---

## Live Training and Visualization

- Training runs headless for maximum performance
- The current best agent can be viewed live in a Pygame window while training continues
- A Tkinter control panel provides:
  - Start and stop training
  - Live visualization of the best agent
  - Generation tracking
  - Per-agent statistics (W/L/S)

---

## Safety and Persistence

The system is designed to be fault-tolerant:

- Best-performing model is saved every generation
- Periodic checkpoints are stored
- Training logs are written to CSV
- Training can resume from the last saved model

### Generated Files

runs_evo_cannon/
├── best_model.npz
├── best_meta.json
├── training_log.csv
└── checkpoints/

---

## Using the Trained AI in the Game

The trained model (best_model.npz) is loaded directly into the main game loop.

- The AI uses the same state representation used during training
- A runtime toggle allows switching between human control and AI control
- The AI selects actions in real time using a forward pass through the trained neural network

---

## Requirements

- Python 3.9 or newer
- pygame
- numpy
- tkinter (included with most Python installations)

Install dependencies:

pip install pygame numpy

---

## How to Run

### Train the AI

python evo_cannon_rl.py

### Play the Game with AI

python main_ai.py

Use the in-game toggle to switch between manual control and AI control.

---

## Educational Value

This project demonstrates:

- Custom environment design for reinforcement learning
- Neuroevolution as an alternative to gradient-based reinforcement learning
- Adaptive mutation strategies
- Model deployment into a real-time application

---

## License

This project is released under the MIT License.
